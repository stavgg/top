import requests
import json
import ollama

class ollamamodel():   
    def __init__(self):
        self.url = "http://localhost:11434/api/generate"
        self.model = "mistral"  # ××•×“×œ ××”×™×¨ ×™×•×ª×¨ ×-llama3

    def get_advice(self, question):
        print("ğŸ“¡ Sending to Ollama via requests...")

        try:
            response = requests.post(
                self.url,
                json={
                    "model": self.model,
                    "prompt": question,
                    "stream": False,
                    "options": {
                        "num_predict": 250  # ×”×’×‘×œ×ª ××•×¨×š ×”×ª×©×•×‘×” ×œ-250 ×ª×•×•×™×
                    }
                }
            )
            response.raise_for_status()

            # ×§×‘×œ×ª ×ª×©×•×‘×” ×›×˜×§×¡×˜
            text = response.text
            # print("ğŸ§¾ Raw response text:")
            # print(text)

            data = json.loads(text)
            return data['response']

        except Exception as e:
            print("âŒ Error communicating with Ollama:", e)
            return f"âš ï¸ Error: {str(e)}"
